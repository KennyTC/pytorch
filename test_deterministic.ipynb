{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJV3uwVJoZrNpXgo7fkiAG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KennyThinh/pytorch/blob/main/test_deterministic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzaF8dl12Yte"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qWNmwpL2U2V"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as f\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import random\n",
        "import os"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RSfb14g4v-1"
      },
      "source": [
        "# for deterministic\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# for using cuda\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QLcOzHt69Zh"
      },
      "source": [
        "# for training\n",
        "trial_num = 1000\n",
        "num_classes = 2\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "learning_rate = 0.00001 #0.000001"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3udATpg7j-Q"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwcwjPwe66QG"
      },
      "source": [
        "if not os.path.exists(f'checkpoints{trial_num}'):\n",
        "  os.mkdir(f'checkpoints{trial_num}')\n",
        "\n",
        "def save_checkpoint(state, epoch):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, \"checkpoints{0}/checkpoint{1}.pth.tar\".format(trial_num,epoch))\n",
        "\n",
        "def load_checkpoint(model, optimizer, epoch_to_load):\n",
        "    print(f\"=> Loading checkpoint {epoch_to_load}\")\n",
        "    checkpoint = torch.load(f'checkpoints{trial_num}/checkpoint{epoch_to_load}.pth.tar')\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "    return model, optimizer"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mC3rWJ56bfm"
      },
      "source": [
        "#check acc on train and test\n",
        "def check_train(loader, model):\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  model.eval() #inform that we are going to evaluate\n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      x = x.reshape(x.shape[0], -1)\n",
        "      scores = model(x) #dim (64,10)      \n",
        "      _, predictions = torch.max(scores, dim=1) #find the max among 10 outputs, so the dim is 1\n",
        "      #predictions ([64])\n",
        "      num_correct += (predictions==y).sum()\n",
        "      num_samples += predictions.size(0) #each time is 64 examples\n",
        "    print(f'--Train Acc {float(num_correct)/float(num_samples)*100:.2f}({num_correct}/{num_samples})')\n",
        "\n",
        "#check acc on train and test\n",
        "def check_val(loader, model):\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  losses = []\n",
        "  model.eval() #inform that we are going to evaluate\n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      x = x.reshape(x.shape[0], -1)\n",
        "      scores = model(x) #dim (64,10)      \n",
        "      loss = criterion(scores, y)\n",
        "      losses.append(loss)\n",
        "\n",
        "      _, predictions = torch.max(scores, dim=1) #find the max among 10 outputs, so the dim is 1\n",
        "      num_correct += (predictions==y).sum()\n",
        "      num_samples += predictions.size(0) #each time is 64 examples\n",
        "    print(f'--Val Loss: {sum(losses)/len(losses)}')\n",
        "    print(f'--Val Acc: {float(num_correct)/float(num_samples)*100:.2f}({num_correct}/{num_samples})')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYNovLim2Z1r",
        "outputId": "92942358-0a9a-4fe1-8a56-fc7800c74388"
      },
      "source": [
        "# create fully connected network\n",
        "class NN(nn.Module):\n",
        "  def __init__(self, input_size, num_classes):\n",
        "    super(NN, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, 50)\n",
        "    self.fc2 = nn.Linear(50, num_classes)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = f.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "#test\n",
        "model = NN(768, 10)\n",
        "x = torch.rand(64,768)\n",
        "print(model(x).shape)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZLN7M1q8a05",
        "outputId": "d0b6e2c9-ddf2-4b17-9c7e-beb7d651bb39"
      },
      "source": [
        "\n",
        "# Transform the data to torch tensors and normalize it \n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307), ((0.3081)))])\n",
        "\n",
        "# Prepare training set and testing set\n",
        "trainset = torchvision.datasets.MNIST('mnist', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST('mnist', train=False, download=True, transform=transform)\n",
        "\n",
        "\n",
        "\n",
        "# Shuffle the indices\n",
        "indices = np.arange(60000)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Build the train loader\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[:55000])) #SubsetRandomSampler and Shuffle=True are mutual exclusive\n",
        "\n",
        "# Build the validation loader\n",
        "val_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[55000:]))\n",
        "\n",
        "# Build the test loader\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=0) \n",
        "\n",
        "\n",
        "# Compute the shape of the training set and testing set\n",
        "trainset_shape = train_loader.dataset.train_data.shape\n",
        "testset_shape = test_loader.dataset.test_data.shape\n",
        "\n",
        "# Print the computed shapes\n",
        "print(trainset_shape, testset_shape)\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:64: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:69: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLDuEopL55pU"
      },
      "source": [
        "model = NN(784, 10).to(device)\n",
        "\n",
        "# Instantiate the cross-entropy loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Instantiate the Adam optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy3OCTeZ82FA",
        "outputId": "b63a720e-0712-4351-81d0-e4caf63270ff"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (fc1): Linear(in_features=784, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjsIPgVk227o",
        "outputId": "68e92036-262c-4ce1-abae-b4f46d0882b9"
      },
      "source": [
        "#train \n",
        "for epoch in range(num_epochs):\n",
        "  losses = []\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "    \n",
        "    data = data.reshape(data.shape[0], -1)        \n",
        "    \n",
        "    #forward\n",
        "    scores = model(data)\n",
        "    loss = criterion(scores, target)\n",
        "\n",
        "    #backward\n",
        "    optimizer.zero_grad() #to clear out gradients of last time\n",
        "    loss.backward()\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    #gradient to update params\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f\"Epoch {epoch}----------------\")\n",
        "  print(f\"--Train Loss: {sum(losses)/len(losses)}\")  \n",
        "  check_train(train_loader, model)  \n",
        "  check_val(val_loader, model)\n",
        "  checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
        "  save_checkpoint(checkpoint, epoch)  "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0----------------\n",
            "--Train Loss: 1.8487000964408697\n",
            "--Train Acc 69.72(38348/55000)\n",
            "--Val Loss: 1.4167749881744385\n",
            "--Val Acc: 70.24(3512/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 1----------------\n",
            "--Train Loss: 1.1640800999347554\n",
            "--Train Acc 79.72(43848/55000)\n",
            "--Val Loss: 0.9441763162612915\n",
            "--Val Acc: 80.20(4010/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 2----------------\n",
            "--Train Loss: 0.8336471954057383\n",
            "--Train Acc 84.21(46318/55000)\n",
            "--Val Loss: 0.7175724506378174\n",
            "--Val Acc: 84.52(4226/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 3----------------\n",
            "--Train Loss: 0.6641962762835414\n",
            "--Train Acc 86.22(47423/55000)\n",
            "--Val Loss: 0.5964516997337341\n",
            "--Val Acc: 86.38(4319/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 4----------------\n",
            "--Train Loss: 0.5653504361939985\n",
            "--Train Acc 87.37(48053/55000)\n",
            "--Val Loss: 0.5161192417144775\n",
            "--Val Acc: 87.56(4378/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 5----------------\n",
            "--Train Loss: 0.5024099657355353\n",
            "--Train Acc 88.19(48504/55000)\n",
            "--Val Loss: 0.46305254101753235\n",
            "--Val Acc: 88.44(4422/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 6----------------\n",
            "--Train Loss: 0.45894914042464524\n",
            "--Train Acc 88.72(48795/55000)\n",
            "--Val Loss: 0.42752018570899963\n",
            "--Val Acc: 88.98(4449/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 7----------------\n",
            "--Train Loss: 0.42772650034275167\n",
            "--Train Acc 89.12(49018/55000)\n",
            "--Val Loss: 0.4051344096660614\n",
            "--Val Acc: 89.38(4469/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 8----------------\n",
            "--Train Loss: 0.4040998175220434\n",
            "--Train Acc 89.49(49222/55000)\n",
            "--Val Loss: 0.3811757564544678\n",
            "--Val Acc: 89.74(4487/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 9----------------\n",
            "--Train Loss: 0.386047858415648\n",
            "--Train Acc 89.82(49399/55000)\n",
            "--Val Loss: 0.366455078125\n",
            "--Val Acc: 90.08(4504/5000)\n",
            "=> Saving checkpoint\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mhba7RxT6UZ4",
        "outputId": "f79c50ca-c0a9-41b9-ba5a-e15e494b9141"
      },
      "source": [
        "for epoch in range(9, 1, -1):\n",
        "  model, optimizer = load_checkpoint(model, optimizer, epoch)\n",
        "  check_train(train_loader, model)\n",
        "  # print(\"Checking accuracy on Validation Set\")\n",
        "  check_val(val_loader, model)\n",
        "  # print(\"Checking accuracy on Test Set\")\n",
        "  # check_val(test_loader, model)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> Loading checkpoint 9\n",
            "--Train Acc 89.82(49399/55000)\n",
            "--Val Loss: 0.3650217652320862\n",
            "--Val Acc: 90.08(4504/5000)\n",
            "=> Loading checkpoint 8\n",
            "--Train Acc 89.49(49222/55000)\n",
            "--Val Loss: 0.37907713651657104\n",
            "--Val Acc: 89.74(4487/5000)\n",
            "=> Loading checkpoint 7\n",
            "--Train Acc 89.12(49018/55000)\n",
            "--Val Loss: 0.40356743335723877\n",
            "--Val Acc: 89.38(4469/5000)\n",
            "=> Loading checkpoint 6\n",
            "--Train Acc 88.72(48795/55000)\n",
            "--Val Loss: 0.4272948205471039\n",
            "--Val Acc: 88.98(4449/5000)\n",
            "=> Loading checkpoint 5\n",
            "--Train Acc 88.19(48504/55000)\n",
            "--Val Loss: 0.46529287099838257\n",
            "--Val Acc: 88.44(4422/5000)\n",
            "=> Loading checkpoint 4\n",
            "--Train Acc 87.37(48053/55000)\n",
            "--Val Loss: 0.5196802616119385\n",
            "--Val Acc: 87.56(4378/5000)\n",
            "=> Loading checkpoint 3\n",
            "--Train Acc 86.22(47423/55000)\n",
            "--Val Loss: 0.5940357446670532\n",
            "--Val Acc: 86.38(4319/5000)\n",
            "=> Loading checkpoint 2\n",
            "--Train Acc 84.21(46318/55000)\n",
            "--Val Loss: 0.7181698679924011\n",
            "--Val Acc: 84.52(4226/5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "245sRCxj0CZ6"
      },
      "source": [
        "PP o tren \n",
        "\n",
        "*   Accracy tren tap val van giu nguyen\n",
        "*   Loss thay doi\n",
        "*   Can test speed, co ve se lau hon ben duoi\n",
        "*   Moi lan run gia tri loss se khac nhau, acc cung khac nhau --> co ve may cai seed khong hoat dong tot. Tuy nhien su khac nhau la ko nhieu, vd loss 0.66 --> 0.67..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Din_Al9hAbFa",
        "outputId": "952c071d-fa3f-485e-de57-2d5a7e044c68"
      },
      "source": [
        "data_loader = {\"train\": train_loader, \"val\": val_loader}\n",
        "dataset_sizes = {\"train\": 55000, \"val\": 5000}\n",
        "model = NN(784, 10).to(device)\n",
        "\n",
        "# Instantiate the cross-entropy loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Instantiate the Adam optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(columns=[\"epoch\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\"])\n",
        "for epoch in range(num_epochs):\n",
        "  print('Epoch {}/{}'.format(epoch, num_epochs-1))\n",
        "  print('-' * 10)\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  for phase in [\"train\", \"val\"]:\n",
        "      if phase == \"train\":\n",
        "          model.train()\n",
        "      else:\n",
        "          model.eval()\n",
        "      current_loss = 0.0\n",
        "      current_corrects = 0\n",
        "\n",
        "      for batch_idx, (data, target) in enumerate(data_loader[phase]):\n",
        "          data = data.to(device)\n",
        "          target = target.to(device)\n",
        "          data = data.reshape(data.shape[0], -1)  \n",
        "          \n",
        "          # forward\n",
        "          scores = model(data)\n",
        "          _, predictions = scores.max(1)\n",
        "          loss = criterion(scores, target)\n",
        "          \n",
        "          if phase == \"train\":\n",
        "              optimizer.zero_grad()\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "          # CPU環境では item() 不要\n",
        "          current_loss += loss.item() * data.size(0) \n",
        "          current_corrects += torch.sum(predictions == target)\n",
        "      \n",
        "      epoch_loss = current_loss / dataset_sizes[phase]\n",
        "      epoch_acc = current_corrects.item() / dataset_sizes[phase]\n",
        "      \n",
        "      print(f'{phase}: loss {epoch_loss}, acc {epoch_acc} ({current_corrects.item()}/{dataset_sizes[phase]})')\n",
        "  checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
        "  save_checkpoint(checkpoint, epoch)  "
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train: loss 1.8966946595105258, acc 0.48761818181818184 (26819/55000)\n",
            "val: loss 1.4539854480743408, acc 0.721 (3605/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 1/9\n",
            "----------\n",
            "train: loss 1.1861037666494196, acc 0.7718363636363637 (42451/55000)\n",
            "val: loss 0.9525429840087891, acc 0.821 (4105/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 2/9\n",
            "----------\n",
            "train: loss 0.8421434968861666, acc 0.8284 (45562/55000)\n",
            "val: loss 0.7197362869262696, acc 0.8544 (4272/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 3/9\n",
            "----------\n",
            "train: loss 0.6684629465623335, acc 0.8527272727272728 (46900/55000)\n",
            "val: loss 0.5923709656715394, acc 0.8682 (4341/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 4/9\n",
            "----------\n",
            "train: loss 0.5677720988100226, acc 0.8672181818181818 (47697/55000)\n",
            "val: loss 0.5146588773727417, acc 0.8802 (4401/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 5/9\n",
            "----------\n",
            "train: loss 0.5032622916698456, acc 0.8770909090909091 (48240/55000)\n",
            "val: loss 0.46274208242893217, acc 0.8858 (4429/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 6/9\n",
            "----------\n",
            "train: loss 0.4589781461585652, acc 0.8839454545454546 (48617/55000)\n",
            "val: loss 0.4260946401596069, acc 0.8926 (4463/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 7/9\n",
            "----------\n",
            "train: loss 0.4269807283856652, acc 0.8890727272727272 (48899/55000)\n",
            "val: loss 0.39892343163490296, acc 0.8962 (4481/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 8/9\n",
            "----------\n",
            "train: loss 0.4028073983192444, acc 0.8932363636363636 (49128/55000)\n",
            "val: loss 0.37849749450683595, acc 0.8992 (4496/5000)\n",
            "=> Saving checkpoint\n",
            "Epoch 9/9\n",
            "----------\n",
            "train: loss 0.38394644214023244, acc 0.8971090909090909 (49341/55000)\n",
            "val: loss 0.3619013295650482, acc 0.9028 (4514/5000)\n",
            "=> Saving checkpoint\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdq5v34kMrlR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff69a354-eeb5-4eab-b206-03f788a166a5"
      },
      "source": [
        "for epoch in range(9, 0, -1):\n",
        "  model, optimizer = load_checkpoint(model, optimizer, epoch)\n",
        "  check_train(train_loader, model)\n",
        "  # print(\"Checking accuracy on Validation Set\")\n",
        "  check_val(val_loader, model)\n",
        "  # print(\"Checking accuracy on Test Set\")\n",
        "  # check_val(test_loader, model)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> Loading checkpoint 9\n",
            "--Train Acc 89.85(49417/55000)\n",
            "--Val Loss: 0.36805450916290283\n",
            "--Val Acc: 90.28(4514/5000)\n",
            "=> Loading checkpoint 8\n",
            "--Train Acc 89.59(49273/55000)\n",
            "--Val Loss: 0.37662434577941895\n",
            "--Val Acc: 89.92(4496/5000)\n",
            "=> Loading checkpoint 7\n",
            "--Train Acc 89.16(49040/55000)\n",
            "--Val Loss: 0.40196922421455383\n",
            "--Val Acc: 89.62(4481/5000)\n",
            "=> Loading checkpoint 6\n",
            "--Train Acc 88.70(48785/55000)\n",
            "--Val Loss: 0.42421549558639526\n",
            "--Val Acc: 89.26(4463/5000)\n",
            "=> Loading checkpoint 5\n",
            "--Train Acc 88.07(48437/55000)\n",
            "--Val Loss: 0.4598385691642761\n",
            "--Val Acc: 88.58(4429/5000)\n",
            "=> Loading checkpoint 4\n",
            "--Train Acc 87.28(48006/55000)\n",
            "--Val Loss: 0.5131676197052002\n",
            "--Val Acc: 88.02(4401/5000)\n",
            "=> Loading checkpoint 3\n",
            "--Train Acc 86.18(47397/55000)\n",
            "--Val Loss: 0.5937952995300293\n",
            "--Val Acc: 86.82(4341/5000)\n",
            "=> Loading checkpoint 2\n",
            "--Train Acc 84.50(46477/55000)\n",
            "--Val Loss: 0.721510112285614\n",
            "--Val Acc: 85.44(4272/5000)\n",
            "=> Loading checkpoint 1\n",
            "--Train Acc 81.21(44666/55000)\n",
            "--Val Loss: 0.9565715789794922\n",
            "--Val Acc: 82.10(4105/5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUYtWeChtPPn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJNPCSCS3ygY"
      },
      "source": [
        "\n",
        "\n",
        "*   So voi cach dung torch.no_grad thi train acc (tinh khi train theo cach nay) se bi thap hon mot chut.\n",
        "*   Moi lan run se khac nhau mot chut, nhung ket qua cuoi cung cung tuong doi gan nhau\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRiTHO3W4PdK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}